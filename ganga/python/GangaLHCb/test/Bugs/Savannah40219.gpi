from GangaLHCb.test import *
addDiracTestSubmitter()

def checkDataSet(dataset):
    isGood = True
    for f in dataset.files:
        if not f.replicas:
            isGood = False
            break
    return isGood

#first check SplitByFiles when we update the cache ourselves
j = Job(application=DaVinci(), backend=TestSubmitter(), splitter= SplitByFiles())
j.application.platform=config['DIRAC']['AllowedPlatforms'][0]
j.inputdata = LHCbDataset(files = [
                                   'LFN:/lhcb/production/DC06/phys-v2-lumi2/00001657/DST/0000/00001657_00000001_5.dst',
                                   'LFN:/lhcb/production/DC06/phys-v2-lumi2/00001657/DST/0000/00001657_00000002_5.dst'])

assert j.inputdata.cacheOutOfDate(), 'Its a new data set so it must be invalid'
j.inputdata.updateReplicaCache()
assert not j.inputdata.cacheOutOfDate(), 'Its no longer a new data set so it must be valid'
checkDataSet(j.inputdata)

data = j.inputdata
date = j.inputdata.cache_date

j.submit()
assert j.inputdata is data, 'We want to preserve the reference'
assert j.inputdata.cache_date == date, 'No cache update should be done (%s, %s)' % (j.inputdata.cache_date, date)
assert checkDataSet(j.inputdata), 'Replicas should be good after submission'
j.kill()

#now do same check with DiracSplitter when we update the cache ourselves
j = Job(application=DaVinci(), backend=TestSubmitter(), splitter= DiracSplitter())
j.application.platform=config['DIRAC']['AllowedPlatforms'][0]
j.inputdata = LHCbDataset(files = [
                                   'LFN:/lhcb/production/DC06/phys-v2-lumi2/00001657/DST/0000/00001657_00000001_5.dst',
                                   'LFN:/lhcb/production/DC06/phys-v2-lumi2/00001657/DST/0000/00001657_00000002_5.dst'])

assert j.inputdata.cacheOutOfDate(), 'Its a new data set so it must be invalid'
j.inputdata.updateReplicaCache()
assert not j.inputdata.cacheOutOfDate(), 'Its no longer a new data set so it must be valid'
checkDataSet(j.inputdata)

data = j.inputdata
date = j.inputdata.cache_date
j.submit()
assert j.inputdata is data, 'We want to preserve the reference'
assert j.inputdata.cache_date == date, 'No cache update should be done'
assert checkDataSet(j.inputdata), 'Replicas should be good after submission'
j.kill()

#now try without first updating the dataset

j = Job(application=DaVinci(), backend=TestSubmitter(), splitter= DiracSplitter())
j.application.platform=config['DIRAC']['AllowedPlatforms'][0]
j.inputdata = LHCbDataset(files = [
                                   'LFN:/lhcb/production/DC06/phys-v2-lumi2/00001657/DST/0000/00001657_00000001_5.dst',
                                   'LFN:/lhcb/production/DC06/phys-v2-lumi2/00001657/DST/0000/00001657_00000002_5.dst'])

assert j.inputdata.cacheOutOfDate(), 'Its a new data set so it must be invalid'
data = j.inputdata
j.submit()

assert j.inputdata is data, 'references should be preserved'
assert not j.inputdata.cacheOutOfDate(), 'Its no longer a new data set so it must be valid'
checkDataSet(j.inputdata)
j.kill()


#finally Ulrik's actual bug
j1 = j.copy()
j1.submit()
assert j1.inputdata.cache_date == j.inputdata.cache_date, 'No cache update should be done'
checkDataSet(j1.inputdata)
j1.kill()

